{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import json\n",
    "import datetime\n",
    "import re\n",
    "import GetOldTweets3 as got\n",
    "import requests\n",
    "\n",
    "# importing libraries for geo-locations\n",
    "from googlemaps import places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Wilson\\\\Documents\\\\capstone\\\\brewery_recommender\\\\data_collection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a json file with your twitter keys and read it in here for privacy\n",
    "with open('../../twitter_keys.json') as f:\n",
    "    keys = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting twitter keys from json file\n",
    "key = keys['key']\n",
    "key_secret = keys['key_secret']\n",
    "token = keys['token']\n",
    "token_secret = keys['token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Twitter API using  account Keys \n",
    "auth_details = tweepy.OAuthHandler(key, key_secret)\n",
    "auth_details.set_access_token(token, token_secret)\n",
    "my_accounts = []\n",
    "\n",
    "# create api instance\n",
    "api = tweepy.API(auth_details, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gswilson6\n",
      "{'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1573684672}}\n"
     ]
    }
   ],
   "source": [
    "# check username and api keys\n",
    "user = api.me()\n",
    "print(user.name)\n",
    "print(api.rate_limit_status()['resources']['search'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the googlemaps_api key from an external file\n",
    "with open (\"../../googlemaps_api_key.txt\", \"r\") as myfile:\n",
    "    api_key = myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the location of the user based on a string query passed into googlemaps_api\n",
    "\n",
    "def places_search(place):\n",
    "    places = [] \n",
    "    for i in range(len(place.split())):\n",
    "        if i < (len(place.split())-1):\n",
    "            places.append(place.split()[i]+'%20')\n",
    "        else:\n",
    "            places.append(place.split()[i])\n",
    "    place_new = ''.join(places)\n",
    "    url = f'https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input={place_new}&inputtype=textquery&fields=geometry&key='+api_key\n",
    "    response = requests.get(url)\n",
    "    resp_json_payload = response.json()\n",
    "    lat = str(resp_json_payload['candidates'][0]['geometry']['location']['lat'])\n",
    "    lng = str(resp_json_payload['candidates'][0]['geometry']['location']['lng'])\n",
    "    return lat+','+lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find beer tweets within a defined radius of the user and returning the tweets\n",
    "# in csv format\n",
    "def beer_tweets_near_me(place, radius):\n",
    "    coords = places_search(place)\n",
    "    snake_places = []\n",
    "    for i in place.split():\n",
    "        snake_places.append(i+'_')\n",
    "    snake_place = ''.join(snake_places)\n",
    "    text = []\n",
    "    user = []\n",
    "    date = []\n",
    "    beer_tweet = {}\n",
    "    n_tweets = 1_000\n",
    "    for i in tweepy.Cursor(api.search, q='brewery', geocode=coords+','+str(radius)+'km').items(n_tweets):\n",
    "        text.append(i.text)\n",
    "        user.append(i.author.screen_name)\n",
    "        date.append(i.created_at)\n",
    "    beer_tweet['tweet'] = text\n",
    "    beer_tweet['user'] = user\n",
    "    beer_tweet['date'] = date\n",
    "    beer_tweets = pd.DataFrame(beer_tweet)\n",
    "    return beer_tweets.to_csv(f'../data/{snake_place}beer_tweets_{radius}_km.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of dsi east coast campuses to loop through\n",
    "DSI_ec_locations = ['Atlanta', 'Austin', 'Boston', 'Chicago', 'DC', 'New York']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating csv's for each dsi east coast location\n",
    "for location in DSI_ec_locations:\n",
    "    beer_tweets_near_me('General Assembly '+location, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_tweets_near_me('Kalamazoo', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
